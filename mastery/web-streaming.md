# Streams

## What is stream?
1. A means of chunking and also creating unilateral or a bi-lateral tunnel for data to not be blocking or restricted by the completeness of a request / response

## Meaningful applications that matter
1. Video, image, and media that allows the decomposition of heavy & long computations to chunks that clients can directly make interactive
2. Live or concurrent experiences
3. Async experiences that are conducted behind-the-scenes with some service that can create affordances for different session windows, state-synchorony for shared or turn-based actions, and the lightweight and instant load on client side that is driven by just-in-time view generation so the clients can be used to grow the loadbalancer

## Why are streams important to focus on now?
Because I don't have experience in the best practices, I would at least like to understand how the tooling could impact the data, analytics, & line-item level hierarchy (mainly impacts what level of segmentation, aggregation, & time slicing you can do later on). Considering this as a 3/10 on the priority score. More concerned about gettig auth up and running right which means adding end points or further breaking down whatever response later is possible. Depending on the consuming clients, it might suffice to do Oath but in certain instances RPC, handshake-brokerage, or public oracles (ETH) could be an interesting application.

As for public data streams, this is a huge huge opportunity to see how the public, independently verifiable, & immutable metadata or record logs could serve to open never-before-captured opps for adoption,
monetization, & 2-sided marketplace.
